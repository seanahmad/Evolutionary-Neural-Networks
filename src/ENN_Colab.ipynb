{"nbformat":4,"nbformat_minor":0,"metadata":{"accelerator":"TPU","colab":{"name":"ENN_Colab.ipynb","provenance":[],"collapsed_sections":[],"machine_shape":"hm","authorship_tag":"ABX9TyMmZx28SGiV67BnEXCK2O/a"},"kernelspec":{"display_name":"Python 3","name":"python3"}},"cells":[{"cell_type":"code","metadata":{"id":"VTkNbNRwr1qF","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1609211339011,"user_tz":300,"elapsed":24791,"user":{"displayName":"Theo Dimitrasopoulos","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhRNhCMR9OSve5rpYHqQ5AxXHb4FT75fg51p-tfkA=s64","userId":"13959094896036405890"}},"outputId":"94beafb9-7a21-4ead-fa4f-b09960be75fd"},"source":["import random\n","import numpy as np\n","import pandas as pd\n","%tensorflow_version 1.x\n","from keras.layers import Dense\n","from keras.models import Sequential\n","from sklearn.metrics import accuracy_score\n","from sklearn.model_selection import train_test_split\n","import numpy as np\n","import pandas_datareader.data as web\n","import matplotlib.pyplot as plt"],"execution_count":null,"outputs":[{"output_type":"stream","text":["TensorFlow 1.x selected.\n"],"name":"stdout"},{"output_type":"stream","text":["Using TensorFlow backend.\n"],"name":"stderr"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"bvFeMOrO-jAW","executionInfo":{"status":"ok","timestamp":1609211339015,"user_tz":300,"elapsed":24776,"user":{"displayName":"Theo Dimitrasopoulos","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhRNhCMR9OSve5rpYHqQ5AxXHb4FT75fg51p-tfkA=s64","userId":"13959094896036405890"}},"outputId":"335fd242-2bcd-4818-8f8c-01d885eb0c67"},"source":["import sys\n","IN_COLAB = 'google.colab' in sys.modules\n","IN_COLAB"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["True"]},"metadata":{"tags":[]},"execution_count":2}]},{"cell_type":"code","metadata":{"id":"7Cg2lWeK-j6i","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1609211339584,"user_tz":300,"elapsed":25339,"user":{"displayName":"Theo Dimitrasopoulos","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhRNhCMR9OSve5rpYHqQ5AxXHb4FT75fg51p-tfkA=s64","userId":"13959094896036405890"}},"outputId":"ca48dc89-4507-4105-a27d-a98a05314721"},"source":["# Use TPU\n","if IN_COLAB:\n","  # TPU Setting\n","  import os\n","  assert os.environ['COLAB_TPU_ADDR'], 'Make sure to select TPU from Edit > Notebook setting > Hardware accelerator'\n","  gfVERSION = \"20200220\"\n","  !curl https://raw.githubusercontent.com/pytorch/xla/master/contrib/scripts/env-setup.py -o pytorch-xla-env-setup.py\n","  !python pytorch-xla-env-setup.py --version $VERSION"],"execution_count":null,"outputs":[{"output_type":"stream","text":["  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n","                                 Dload  Upload   Total   Spent    Left  Speed\n","100  5116  100  5116    0     0  28109      0 --:--:-- --:--:-- --:--:-- 28109\n","usage: pytorch-xla-env-setup.py [-h] [--version VERSION]\n","                                [--apt-packages APT_PACKAGES [APT_PACKAGES ...]]\n","                                [--tpu TPU]\n","pytorch-xla-env-setup.py: error: argument --version: expected one argument\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"SgGs45istKvq"},"source":["class ENN(Sequential):\n","    def __init__(self, wts_sub=None):\n","        super().__init__()\n","        if wts_sub is None:\n","            layer1 = Dense(1, input_shape=(1,), activation='sigmoid')\n","            layer2 = Dense(3, activation='sigmoid')\n","            layer3 = Dense(3, activation='sigmoid')\n","            layer4 = Dense(3, activation='sigmoid')\n","            layer5 = Dense(1, activation='sigmoid')\n","            self.add(layer1)\n","            self.add(layer2)\n","            self.add(layer3)\n","            self.add(layer4)\n","            self.add(layer5)\n","        else:\n","            self.add(Dense(1,input_shape=(1,),activation='sigmoid',weights=[wts_sub[0], np.zeros(1)]))\n","            self.add(Dense(3,activation='sigmoid',weights=[wts_sub[1], np.zeros(3)]))\n","            self.add(Dense(3,activation='sigmoid',weights=[wts_sub[2], np.zeros(3)]))\n","            self.add(Dense(3,activation='sigmoid',weights=[wts_sub[3], np.zeros(3)]))\n","            self.add(Dense(1,activation='sigmoid',weights=[wts_sub[4], np.zeros(1)]))\n","\n","    def f_propagation(self, X_train, y_train):\n","        y_predicted = self.predict(X_train.values)\n","        self.fitness = accuracy_score(y_train, y_predicted.round())\n","\n","    def train(self, epochs):\n","        self.compile(optimizer='rmsprop',loss='binary_crossentropy',metrics=['accuracy'])\n","        self.fit(X_train.values, y_train.values, epochs=epochs)\n","\n","def mutation(wts_sub):\n","    choose = random.randint(0, len(wts_sub)-1)\n","    mut = random.uniform(0, 1)\n","    if mut >= .5:\n","        wts_sub[choose] *= random.randint(2, 5)\n","    else:\n","        pass\n","\n","def cross(nn1, nn2):\n","    nn1_weights = []\n","    nn2_weights = []\n","    wts_sub = []\n","    for layer in nn1.layers:\n","        nn1_weights.append(layer.get_weights()[0])\n","\n","    for layer in nn2.layers:\n","        nn2_weights.append(layer.get_weights()[0])\n","\n","    for i in range(0, len(nn1_weights)):\n","        split = random.randint(0, np.shape(nn1_weights[i])[1]-1)\n","        for j in range(split, np.shape(nn1_weights[i])[1]-1):\n","            nn1_weights[i][:, j] = nn2_weights[i][:, j]\n","\n","        wts_sub.append(nn1_weights[i])\n","\n","    mutation(wts_sub)\n","\n","    child = ENN(wts_sub)\n","    return child\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"SncEefl_tPNe","colab":{"base_uri":"https://localhost:8080/","height":402},"executionInfo":{"status":"ok","timestamp":1609211591482,"user_tz":300,"elapsed":935,"user":{"displayName":"Theo Dimitrasopoulos","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhRNhCMR9OSve5rpYHqQ5AxXHb4FT75fg51p-tfkA=s64","userId":"13959094896036405890"}},"outputId":"a487cb9a-341d-4112-8b68-b53ebd36c7e2"},"source":["prices = pd.DataFrame()\n","tickers = ['^DJI']\n","for i in tickers:\n","    tmp = web.DataReader(i, 'yahoo', '1/1/2007', '01/12/2020')\n","    prices[i] = tmp['Adj Close']\n","\n","prices['Percent Change'] = prices.pct_change()\n","\n","def set_signal(column):\n","    if column['Percent Change'] < -0.0050:\n","        signal = -1\n","    elif column['Percent Change'] > 0.0050:\n","        signal = 1\n","    else:\n","        signal = 0\n","    return signal\n","\n","prices['Liquidate'] = prices.apply(set_signal, axis=1)\n","prices = prices.replace(np.nan,0)\n","prices = prices.drop(['^DJI'], axis=1)\n","prices.reset_index(inplace=True,drop=True)\n","prices"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>Percent Change</th>\n","      <th>Liquidate</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>0.000000</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>0.000495</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>-0.006625</td>\n","      <td>-1</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>0.002055</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>-0.000555</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>...</th>\n","      <td>...</td>\n","      <td>...</td>\n","    </tr>\n","    <tr>\n","      <th>3274</th>\n","      <td>0.002392</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>3275</th>\n","      <td>-0.004170</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>3276</th>\n","      <td>0.005647</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>3277</th>\n","      <td>0.007369</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>3278</th>\n","      <td>-0.004598</td>\n","      <td>0</td>\n","    </tr>\n","  </tbody>\n","</table>\n","<p>3279 rows Ã— 2 columns</p>\n","</div>"],"text/plain":["      Percent Change  Liquidate\n","0           0.000000          0\n","1           0.000495          0\n","2          -0.006625         -1\n","3           0.002055          0\n","4          -0.000555          0\n","...              ...        ...\n","3274        0.002392          0\n","3275       -0.004170          0\n","3276        0.005647          1\n","3277        0.007369          1\n","3278       -0.004598          0\n","\n","[3279 rows x 2 columns]"]},"metadata":{"tags":[]},"execution_count":8}]},{"cell_type":"code","metadata":{"id":"I1rZrGHVubrW","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1609211596906,"user_tz":300,"elapsed":275,"user":{"displayName":"Theo Dimitrasopoulos","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhRNhCMR9OSve5rpYHqQ5AxXHb4FT75fg51p-tfkA=s64","userId":"13959094896036405890"}},"outputId":"7f962355-282c-46e9-9fcc-871a9652274d"},"source":["X = prices['Percent Change']\n","X = 100*X.round(8)\n","X = X.astype(np.float32)\n","print(X.astype(np.float32))\n","y = prices.drop(['Percent Change'], axis=1)\n","#y = y.astype(np.float32)\n","print(y)\n","X_train, X_test, y_train, y_test = train_test_split(X, y)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["0       0.000000\n","1       0.049468\n","2      -0.662469\n","3       0.205521\n","4      -0.055464\n","          ...   \n","3274    0.239219\n","3275   -0.417028\n","3276    0.564693\n","3277    0.736858\n","3278   -0.459755\n","Name: Percent Change, Length: 3279, dtype: float32\n","      Liquidate\n","0             0\n","1             0\n","2            -1\n","3             0\n","4             0\n","...         ...\n","3274          0\n","3275          0\n","3276          1\n","3277          1\n","3278          0\n","\n","[3279 rows x 1 columns]\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"aRDt17USuwJP","colab":{"base_uri":"https://localhost:8080/"},"outputId":"885cd634-fb0b-4822-e094-d6492b105658"},"source":["networks = []\n","pool = []\n","gen = 0\n","n = 10\n","\n","for i in range(0, n):\n","    networks.append(ENN())\n","\n","fit_max = 0\n","\n","wts_opt = []\n","\n","while fit_max < .9:\n","    gen += 1\n","    print('Generation', gen)\n","\n","    for nn in networks:\n","        nn.f_propagation(X_train, y_train)\n","        pool.append(nn)\n","\n","    networks.clear()\n","\n","    pool = sorted(pool, key=lambda x: x.fitness)\n","    pool.reverse()\n","\n","    for i in range(0, len(pool)):\n","        if pool[i].fitness > fit_max:\n","            fit_max = pool[i].fitness\n","            print('Fitness Score: ', fit_max)\n","            wts_opt = []\n","            for layer in pool[i].layers:\n","              wts_opt.append(layer.get_weights()[0])\n","            print(wts_opt)\n","\n","    for i in range(0, 5):\n","        for j in range(0, 2):\n","            temp = cross(pool[i], random.choice(pool))\n","            networks.append(temp)\n","\n","portfolio_enn = ENN(wts_opt)\n","portfolio_enn.train(10)\n","y_predicted = portfolio_enn.predict(X_test.values)\n","print('Accuracy: %.2f' % accuracy_score(y_test, y_predicted.round()))"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Generation 1\n","Fitness Score:  0.5282635217568117\n","[array([[1.042898]], dtype=float32), array([[ 0.460626  , -1.1236215 , -0.16491425]], dtype=float32), array([[-0.7738557 , -0.8626251 ,  0.37523603],\n","       [-0.4521742 , -0.8964057 , -0.24659395],\n","       [-0.16870809,  0.9809499 ,  0.4639206 ]], dtype=float32), array([[ 0.46616197, -0.69974375,  0.38495588],\n","       [-0.5864825 , -0.954437  , -0.20068097],\n","       [-0.75203633,  0.22171378, -0.3454697 ]], dtype=float32), array([[-0.05194068],\n","       [-0.41252893],\n","       [-0.3281436 ]], dtype=float32)]\n","Generation 2\n","Generation 3\n","Generation 4\n","Generation 5\n","Generation 6\n","Generation 7\n","Generation 8\n","Generation 9\n","Generation 10\n","Generation 11\n","Generation 12\n","Generation 13\n","Generation 14\n","Generation 15\n","Generation 16\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"Wbdb65jLNB8f","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1609211773528,"user_tz":300,"elapsed":58048,"user":{"displayName":"Theo Dimitrasopoulos","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhRNhCMR9OSve5rpYHqQ5AxXHb4FT75fg51p-tfkA=s64","userId":"13959094896036405890"}},"outputId":"47aab8e9-a62f-460f-d378-7387ddc8a8d9"},"source":["portfolio_nn = Sequential()\n","portfolio_nn.add(Dense(1, input_shape=(1,), activation='sigmoid'))\n","portfolio_nn.add(Dense(3, activation='sigmoid'))\n","portfolio_nn.add(Dense(3, activation='sigmoid'))\n","portfolio_nn.add(Dense(3, activation='sigmoid'))\n","portfolio_nn.add(Dense(1, activation='sigmoid'))\n","portfolio_nn.compile(optimizer='rmsprop',loss='hinge',metrics=['accuracy'])\n","portfolio_nn.fit(X_train.values, y_train.values, epochs=500)\n","y_predicted = portfolio_nn.predict(X_test.values)\n","y_predicted = np.around(y_predicted, 0)\n","print('Test Accuracy: %.2f' % accuracy_score(y_test, y_predicted.round()))"],"execution_count":null,"outputs":[{"output_type":"stream","text":["WARNING:tensorflow:From /tensorflow-1.15.2/python3.6/tensorflow_core/python/ops/math_grad.py:1424: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Use tf.where in 2.0, which has the same broadcast rule as np.where\n","Epoch 1/500\n","2459/2459 [==============================] - 0s 195us/step - loss: 0.9783 - accuracy: 0.2554\n","Epoch 2/500\n","2459/2459 [==============================] - 0s 55us/step - loss: 0.9774 - accuracy: 0.2554\n","Epoch 3/500\n","2459/2459 [==============================] - 0s 51us/step - loss: 0.9765 - accuracy: 0.2554\n","Epoch 4/500\n","2459/2459 [==============================] - 0s 49us/step - loss: 0.9756 - accuracy: 0.2554\n","Epoch 5/500\n","2459/2459 [==============================] - 0s 49us/step - loss: 0.9747 - accuracy: 0.2554\n","Epoch 6/500\n","2459/2459 [==============================] - 0s 48us/step - loss: 0.9738 - accuracy: 0.2554\n","Epoch 7/500\n","2459/2459 [==============================] - 0s 49us/step - loss: 0.9730 - accuracy: 0.2554\n","Epoch 8/500\n","2459/2459 [==============================] - 0s 49us/step - loss: 0.9721 - accuracy: 0.2554\n","Epoch 9/500\n","2459/2459 [==============================] - 0s 49us/step - loss: 0.9712 - accuracy: 0.2554\n","Epoch 10/500\n","2459/2459 [==============================] - 0s 50us/step - loss: 0.9703 - accuracy: 0.2554\n","Epoch 11/500\n","2459/2459 [==============================] - 0s 50us/step - loss: 0.9695 - accuracy: 0.2554\n","Epoch 12/500\n","2459/2459 [==============================] - 0s 50us/step - loss: 0.9687 - accuracy: 0.2554\n","Epoch 13/500\n","2459/2459 [==============================] - 0s 48us/step - loss: 0.9679 - accuracy: 0.2554\n","Epoch 14/500\n","2459/2459 [==============================] - 0s 49us/step - loss: 0.9670 - accuracy: 0.2554\n","Epoch 15/500\n","2459/2459 [==============================] - 0s 49us/step - loss: 0.9662 - accuracy: 0.2554\n","Epoch 16/500\n","2459/2459 [==============================] - 0s 49us/step - loss: 0.9653 - accuracy: 0.2554\n","Epoch 17/500\n","2459/2459 [==============================] - 0s 50us/step - loss: 0.9645 - accuracy: 0.2554\n","Epoch 18/500\n","2459/2459 [==============================] - 0s 49us/step - loss: 0.9636 - accuracy: 0.2554\n","Epoch 19/500\n","2459/2459 [==============================] - 0s 51us/step - loss: 0.9697 - accuracy: 0.2554\n","Epoch 20/500\n","2459/2459 [==============================] - 0s 50us/step - loss: 0.9616 - accuracy: 0.2554\n","Epoch 21/500\n","2459/2459 [==============================] - 0s 49us/step - loss: 0.9605 - accuracy: 0.2554\n","Epoch 22/500\n","2459/2459 [==============================] - 0s 49us/step - loss: 0.9591 - accuracy: 0.2554\n","Epoch 23/500\n","2459/2459 [==============================] - 0s 49us/step - loss: 0.9577 - accuracy: 0.2554\n","Epoch 24/500\n","2459/2459 [==============================] - 0s 49us/step - loss: 0.9559 - accuracy: 0.2554\n","Epoch 25/500\n","2459/2459 [==============================] - 0s 49us/step - loss: 0.9539 - accuracy: 0.2554\n","Epoch 26/500\n","2459/2459 [==============================] - 0s 49us/step - loss: 0.9515 - accuracy: 0.2554\n","Epoch 27/500\n","2459/2459 [==============================] - 0s 51us/step - loss: 0.9487 - accuracy: 0.2554\n","Epoch 28/500\n","2459/2459 [==============================] - 0s 49us/step - loss: 0.9456 - accuracy: 0.2554\n","Epoch 29/500\n","2459/2459 [==============================] - 0s 49us/step - loss: 0.9418 - accuracy: 0.2554\n","Epoch 30/500\n","2459/2459 [==============================] - 0s 46us/step - loss: 0.9370 - accuracy: 0.2554\n","Epoch 31/500\n","2459/2459 [==============================] - 0s 47us/step - loss: 0.9319 - accuracy: 0.2554\n","Epoch 32/500\n","2459/2459 [==============================] - 0s 47us/step - loss: 0.9264 - accuracy: 0.2554\n","Epoch 33/500\n","2459/2459 [==============================] - 0s 47us/step - loss: 0.9197 - accuracy: 0.2554\n","Epoch 34/500\n","2459/2459 [==============================] - 0s 47us/step - loss: 0.9126 - accuracy: 0.2554\n","Epoch 35/500\n","2459/2459 [==============================] - 0s 47us/step - loss: 0.9049 - accuracy: 0.2554\n","Epoch 36/500\n","2459/2459 [==============================] - 0s 46us/step - loss: 0.8964 - accuracy: 0.2554\n","Epoch 37/500\n","2459/2459 [==============================] - 0s 46us/step - loss: 0.8872 - accuracy: 0.2651\n","Epoch 38/500\n","2459/2459 [==============================] - 0s 46us/step - loss: 0.8778 - accuracy: 0.3257\n","Epoch 39/500\n","2459/2459 [==============================] - 0s 46us/step - loss: 0.8683 - accuracy: 0.3729\n","Epoch 40/500\n","2459/2459 [==============================] - 0s 46us/step - loss: 0.8587 - accuracy: 0.4099\n","Epoch 41/500\n","2459/2459 [==============================] - 0s 47us/step - loss: 0.8489 - accuracy: 0.4319\n","Epoch 42/500\n","2459/2459 [==============================] - 0s 47us/step - loss: 0.8398 - accuracy: 0.4522\n","Epoch 43/500\n","2459/2459 [==============================] - 0s 45us/step - loss: 0.8307 - accuracy: 0.4595\n","Epoch 44/500\n","2459/2459 [==============================] - 0s 45us/step - loss: 0.8219 - accuracy: 0.4693\n","Epoch 45/500\n","2459/2459 [==============================] - 0s 45us/step - loss: 0.8137 - accuracy: 0.4843\n","Epoch 46/500\n","2459/2459 [==============================] - 0s 47us/step - loss: 0.8059 - accuracy: 0.4900\n","Epoch 47/500\n","2459/2459 [==============================] - 0s 48us/step - loss: 0.7991 - accuracy: 0.4965\n","Epoch 48/500\n","2459/2459 [==============================] - 0s 47us/step - loss: 0.7928 - accuracy: 0.5031\n","Epoch 49/500\n","2459/2459 [==============================] - 0s 47us/step - loss: 0.7871 - accuracy: 0.5063\n","Epoch 50/500\n","2459/2459 [==============================] - 0s 46us/step - loss: 0.7820 - accuracy: 0.5096\n","Epoch 51/500\n","2459/2459 [==============================] - 0s 47us/step - loss: 0.7776 - accuracy: 0.5108\n","Epoch 52/500\n","2459/2459 [==============================] - 0s 47us/step - loss: 0.7735 - accuracy: 0.5132\n","Epoch 53/500\n","2459/2459 [==============================] - 0s 47us/step - loss: 0.7700 - accuracy: 0.5148\n","Epoch 54/500\n","2459/2459 [==============================] - 0s 47us/step - loss: 0.7669 - accuracy: 0.5153\n","Epoch 55/500\n","2459/2459 [==============================] - 0s 47us/step - loss: 0.7642 - accuracy: 0.5169\n","Epoch 56/500\n","2459/2459 [==============================] - 0s 47us/step - loss: 0.7668 - accuracy: 0.5197\n","Epoch 57/500\n","2459/2459 [==============================] - 0s 46us/step - loss: 0.7600 - accuracy: 0.5214\n","Epoch 58/500\n","2459/2459 [==============================] - 0s 46us/step - loss: 0.7582 - accuracy: 0.5246\n","Epoch 59/500\n","2459/2459 [==============================] - 0s 47us/step - loss: 0.7566 - accuracy: 0.5270\n","Epoch 60/500\n","2459/2459 [==============================] - 0s 46us/step - loss: 0.7552 - accuracy: 0.5262\n","Epoch 61/500\n","2459/2459 [==============================] - 0s 48us/step - loss: 0.7539 - accuracy: 0.5287\n","Epoch 62/500\n","2459/2459 [==============================] - 0s 47us/step - loss: 0.7529 - accuracy: 0.5299\n","Epoch 63/500\n","2459/2459 [==============================] - 0s 47us/step - loss: 0.7519 - accuracy: 0.5327\n","Epoch 64/500\n","2459/2459 [==============================] - 0s 48us/step - loss: 0.7511 - accuracy: 0.5340\n","Epoch 65/500\n","2459/2459 [==============================] - 0s 46us/step - loss: 0.7503 - accuracy: 0.5348\n","Epoch 66/500\n","2459/2459 [==============================] - 0s 47us/step - loss: 0.7497 - accuracy: 0.5356\n","Epoch 67/500\n","2459/2459 [==============================] - 0s 47us/step - loss: 0.7491 - accuracy: 0.5356\n","Epoch 68/500\n","2459/2459 [==============================] - 0s 47us/step - loss: 0.7486 - accuracy: 0.5384\n","Epoch 69/500\n","2459/2459 [==============================] - 0s 48us/step - loss: 0.7481 - accuracy: 0.5380\n","Epoch 70/500\n","2459/2459 [==============================] - 0s 46us/step - loss: 0.7477 - accuracy: 0.5392\n","Epoch 71/500\n","2459/2459 [==============================] - 0s 45us/step - loss: 0.7474 - accuracy: 0.5397\n","Epoch 72/500\n","2459/2459 [==============================] - 0s 45us/step - loss: 0.7471 - accuracy: 0.5397\n","Epoch 73/500\n","2459/2459 [==============================] - 0s 45us/step - loss: 0.7468 - accuracy: 0.5413\n","Epoch 74/500\n","2459/2459 [==============================] - 0s 44us/step - loss: 0.7514 - accuracy: 0.5421\n","Epoch 75/500\n","2459/2459 [==============================] - 0s 45us/step - loss: 0.7464 - accuracy: 0.5433\n","Epoch 76/500\n","2459/2459 [==============================] - 0s 44us/step - loss: 0.7462 - accuracy: 0.5449\n","Epoch 77/500\n","2459/2459 [==============================] - 0s 43us/step - loss: 0.7460 - accuracy: 0.5449\n","Epoch 78/500\n","2459/2459 [==============================] - 0s 44us/step - loss: 0.7459 - accuracy: 0.5449\n","Epoch 79/500\n","2459/2459 [==============================] - 0s 44us/step - loss: 0.7457 - accuracy: 0.5449\n","Epoch 80/500\n","2459/2459 [==============================] - 0s 44us/step - loss: 0.7456 - accuracy: 0.5449\n","Epoch 81/500\n","2459/2459 [==============================] - 0s 46us/step - loss: 0.7455 - accuracy: 0.5449\n","Epoch 82/500\n","2459/2459 [==============================] - 0s 45us/step - loss: 0.7454 - accuracy: 0.5449\n","Epoch 83/500\n","2459/2459 [==============================] - 0s 44us/step - loss: 0.7453 - accuracy: 0.5453\n","Epoch 84/500\n","2459/2459 [==============================] - 0s 43us/step - loss: 0.7452 - accuracy: 0.5453\n","Epoch 85/500\n","2459/2459 [==============================] - 0s 45us/step - loss: 0.7452 - accuracy: 0.5453\n","Epoch 86/500\n","2459/2459 [==============================] - 0s 51us/step - loss: 0.7451 - accuracy: 0.5453\n","Epoch 87/500\n","2459/2459 [==============================] - 0s 44us/step - loss: 0.7451 - accuracy: 0.5453\n","Epoch 88/500\n","2459/2459 [==============================] - 0s 45us/step - loss: 0.7450 - accuracy: 0.5453\n","Epoch 89/500\n","2459/2459 [==============================] - 0s 46us/step - loss: 0.7450 - accuracy: 0.5453\n","Epoch 90/500\n","2459/2459 [==============================] - 0s 45us/step - loss: 0.7449 - accuracy: 0.5458\n","Epoch 91/500\n","2459/2459 [==============================] - 0s 44us/step - loss: 0.7449 - accuracy: 0.5458\n","Epoch 92/500\n","2459/2459 [==============================] - 0s 45us/step - loss: 0.7449 - accuracy: 0.5458\n","Epoch 93/500\n","2459/2459 [==============================] - 0s 45us/step - loss: 0.7448 - accuracy: 0.5458\n","Epoch 94/500\n","2459/2459 [==============================] - 0s 44us/step - loss: 0.7448 - accuracy: 0.5453\n","Epoch 95/500\n","2459/2459 [==============================] - 0s 44us/step - loss: 0.7448 - accuracy: 0.5458\n","Epoch 96/500\n","2459/2459 [==============================] - 0s 45us/step - loss: 0.7448 - accuracy: 0.5453\n","Epoch 97/500\n","2459/2459 [==============================] - 0s 45us/step - loss: 0.7448 - accuracy: 0.5453\n","Epoch 98/500\n","2459/2459 [==============================] - 0s 44us/step - loss: 0.7447 - accuracy: 0.5453\n","Epoch 99/500\n","2459/2459 [==============================] - 0s 44us/step - loss: 0.7447 - accuracy: 0.5453\n","Epoch 100/500\n","2459/2459 [==============================] - 0s 44us/step - loss: 0.7447 - accuracy: 0.5453\n","Epoch 101/500\n","2459/2459 [==============================] - 0s 44us/step - loss: 0.7447 - accuracy: 0.5453\n","Epoch 102/500\n","2459/2459 [==============================] - 0s 47us/step - loss: 0.7447 - accuracy: 0.5453\n","Epoch 103/500\n","2459/2459 [==============================] - 0s 45us/step - loss: 0.7447 - accuracy: 0.5453\n","Epoch 104/500\n","2459/2459 [==============================] - 0s 47us/step - loss: 0.7447 - accuracy: 0.5453\n","Epoch 105/500\n","2459/2459 [==============================] - 0s 45us/step - loss: 0.7447 - accuracy: 0.5453\n","Epoch 106/500\n","2459/2459 [==============================] - 0s 45us/step - loss: 0.7447 - accuracy: 0.5453\n","Epoch 107/500\n","2459/2459 [==============================] - 0s 45us/step - loss: 0.7447 - accuracy: 0.5453\n","Epoch 108/500\n","2459/2459 [==============================] - 0s 45us/step - loss: 0.7447 - accuracy: 0.5453\n","Epoch 109/500\n","2459/2459 [==============================] - 0s 45us/step - loss: 0.7446 - accuracy: 0.5458\n","Epoch 110/500\n","2459/2459 [==============================] - 0s 47us/step - loss: 0.7446 - accuracy: 0.5458\n","Epoch 111/500\n","2459/2459 [==============================] - 0s 45us/step - loss: 0.7446 - accuracy: 0.5458\n","Epoch 112/500\n","2459/2459 [==============================] - 0s 43us/step - loss: 0.7446 - accuracy: 0.5462\n","Epoch 113/500\n","2459/2459 [==============================] - 0s 44us/step - loss: 0.7446 - accuracy: 0.5462\n","Epoch 114/500\n","2459/2459 [==============================] - 0s 44us/step - loss: 0.7446 - accuracy: 0.5462\n","Epoch 115/500\n","2459/2459 [==============================] - 0s 44us/step - loss: 0.7446 - accuracy: 0.5466\n","Epoch 116/500\n","2459/2459 [==============================] - 0s 44us/step - loss: 0.7446 - accuracy: 0.5466\n","Epoch 117/500\n","2459/2459 [==============================] - 0s 45us/step - loss: 0.7446 - accuracy: 0.5466\n","Epoch 118/500\n","2459/2459 [==============================] - 0s 44us/step - loss: 0.7446 - accuracy: 0.5466\n","Epoch 119/500\n","2459/2459 [==============================] - 0s 44us/step - loss: 0.7446 - accuracy: 0.5470\n","Epoch 120/500\n","2459/2459 [==============================] - 0s 45us/step - loss: 0.7446 - accuracy: 0.5470\n","Epoch 121/500\n","2459/2459 [==============================] - 0s 44us/step - loss: 0.7446 - accuracy: 0.5470\n","Epoch 122/500\n","2459/2459 [==============================] - 0s 44us/step - loss: 0.7446 - accuracy: 0.5470\n","Epoch 123/500\n","2459/2459 [==============================] - 0s 44us/step - loss: 0.7446 - accuracy: 0.5474\n","Epoch 124/500\n","2459/2459 [==============================] - 0s 43us/step - loss: 0.7446 - accuracy: 0.5474\n","Epoch 125/500\n","2459/2459 [==============================] - 0s 44us/step - loss: 0.7446 - accuracy: 0.5474\n","Epoch 126/500\n","2459/2459 [==============================] - 0s 44us/step - loss: 0.7446 - accuracy: 0.5474\n","Epoch 127/500\n","2459/2459 [==============================] - 0s 44us/step - loss: 0.7446 - accuracy: 0.5474\n","Epoch 128/500\n","2459/2459 [==============================] - 0s 44us/step - loss: 0.7446 - accuracy: 0.5474\n","Epoch 129/500\n","2459/2459 [==============================] - 0s 44us/step - loss: 0.7446 - accuracy: 0.5474\n","Epoch 130/500\n","2459/2459 [==============================] - 0s 44us/step - loss: 0.7446 - accuracy: 0.5474\n","Epoch 131/500\n","2459/2459 [==============================] - 0s 45us/step - loss: 0.7446 - accuracy: 0.5474\n","Epoch 132/500\n","2459/2459 [==============================] - 0s 45us/step - loss: 0.7446 - accuracy: 0.5474\n","Epoch 133/500\n","2459/2459 [==============================] - 0s 44us/step - loss: 0.7446 - accuracy: 0.5474\n","Epoch 134/500\n","2459/2459 [==============================] - 0s 45us/step - loss: 0.7446 - accuracy: 0.5474\n","Epoch 135/500\n","2459/2459 [==============================] - 0s 44us/step - loss: 0.7446 - accuracy: 0.5474\n","Epoch 136/500\n","2459/2459 [==============================] - 0s 45us/step - loss: 0.7479 - accuracy: 0.5474\n","Epoch 137/500\n","2459/2459 [==============================] - 0s 45us/step - loss: 0.7446 - accuracy: 0.5474\n","Epoch 138/500\n","2459/2459 [==============================] - 0s 45us/step - loss: 0.7446 - accuracy: 0.5474\n","Epoch 139/500\n","2459/2459 [==============================] - 0s 45us/step - loss: 0.7446 - accuracy: 0.5474\n","Epoch 140/500\n","2459/2459 [==============================] - 0s 46us/step - loss: 0.7471 - accuracy: 0.5474\n","Epoch 141/500\n","2459/2459 [==============================] - 0s 45us/step - loss: 0.7446 - accuracy: 0.5474\n","Epoch 142/500\n","2459/2459 [==============================] - 0s 45us/step - loss: 0.7446 - accuracy: 0.5474\n","Epoch 143/500\n","2459/2459 [==============================] - 0s 44us/step - loss: 0.7446 - accuracy: 0.5474\n","Epoch 144/500\n","2459/2459 [==============================] - 0s 44us/step - loss: 0.7446 - accuracy: 0.5474\n","Epoch 145/500\n","2459/2459 [==============================] - 0s 44us/step - loss: 0.7446 - accuracy: 0.5474\n","Epoch 146/500\n","2459/2459 [==============================] - 0s 44us/step - loss: 0.7446 - accuracy: 0.5474\n","Epoch 147/500\n","2459/2459 [==============================] - 0s 43us/step - loss: 0.7446 - accuracy: 0.5474\n","Epoch 148/500\n","2459/2459 [==============================] - 0s 44us/step - loss: 0.7446 - accuracy: 0.5474\n","Epoch 149/500\n","2459/2459 [==============================] - 0s 44us/step - loss: 0.7446 - accuracy: 0.5474\n","Epoch 150/500\n","2459/2459 [==============================] - 0s 44us/step - loss: 0.7446 - accuracy: 0.5474\n","Epoch 151/500\n","2459/2459 [==============================] - 0s 44us/step - loss: 0.7446 - accuracy: 0.5474\n","Epoch 152/500\n","2459/2459 [==============================] - 0s 44us/step - loss: 0.7446 - accuracy: 0.5474\n","Epoch 153/500\n","2459/2459 [==============================] - 0s 45us/step - loss: 0.7446 - accuracy: 0.5474\n","Epoch 154/500\n","2459/2459 [==============================] - 0s 45us/step - loss: 0.7446 - accuracy: 0.5474\n","Epoch 155/500\n","2459/2459 [==============================] - 0s 43us/step - loss: 0.7446 - accuracy: 0.5474\n","Epoch 156/500\n","2459/2459 [==============================] - 0s 44us/step - loss: 0.7446 - accuracy: 0.5474\n","Epoch 157/500\n","2459/2459 [==============================] - 0s 44us/step - loss: 0.7446 - accuracy: 0.5474\n","Epoch 158/500\n","2459/2459 [==============================] - 0s 43us/step - loss: 0.7446 - accuracy: 0.5474\n","Epoch 159/500\n","2459/2459 [==============================] - 0s 44us/step - loss: 0.7446 - accuracy: 0.5474\n","Epoch 160/500\n","2459/2459 [==============================] - 0s 45us/step - loss: 0.7446 - accuracy: 0.5474\n","Epoch 161/500\n","2459/2459 [==============================] - 0s 44us/step - loss: 0.7446 - accuracy: 0.5474\n","Epoch 162/500\n","2459/2459 [==============================] - 0s 43us/step - loss: 0.7446 - accuracy: 0.5474\n","Epoch 163/500\n","2459/2459 [==============================] - 0s 44us/step - loss: 0.7446 - accuracy: 0.5474\n","Epoch 164/500\n","2459/2459 [==============================] - 0s 43us/step - loss: 0.7446 - accuracy: 0.5474\n","Epoch 165/500\n","2459/2459 [==============================] - 0s 43us/step - loss: 0.7446 - accuracy: 0.5474\n","Epoch 166/500\n","2459/2459 [==============================] - 0s 43us/step - loss: 0.7446 - accuracy: 0.5474\n","Epoch 167/500\n","2459/2459 [==============================] - 0s 45us/step - loss: 0.7446 - accuracy: 0.5474\n","Epoch 168/500\n","2459/2459 [==============================] - 0s 46us/step - loss: 0.7446 - accuracy: 0.5474\n","Epoch 169/500\n","2459/2459 [==============================] - 0s 46us/step - loss: 0.7446 - accuracy: 0.5474\n","Epoch 170/500\n","2459/2459 [==============================] - 0s 45us/step - loss: 0.7446 - accuracy: 0.5474\n","Epoch 171/500\n","2459/2459 [==============================] - 0s 45us/step - loss: 0.7446 - accuracy: 0.5474\n","Epoch 172/500\n","2459/2459 [==============================] - 0s 45us/step - loss: 0.7446 - accuracy: 0.5474\n","Epoch 173/500\n","2459/2459 [==============================] - 0s 44us/step - loss: 0.7446 - accuracy: 0.5474\n","Epoch 174/500\n","2459/2459 [==============================] - 0s 45us/step - loss: 0.7446 - accuracy: 0.5474\n","Epoch 175/500\n","2459/2459 [==============================] - 0s 44us/step - loss: 0.7446 - accuracy: 0.5474\n","Epoch 176/500\n","2459/2459 [==============================] - 0s 44us/step - loss: 0.7446 - accuracy: 0.5474\n","Epoch 177/500\n","2459/2459 [==============================] - 0s 44us/step - loss: 0.7475 - accuracy: 0.5474\n","Epoch 178/500\n","2459/2459 [==============================] - 0s 45us/step - loss: 0.7446 - accuracy: 0.5474\n","Epoch 179/500\n","2459/2459 [==============================] - 0s 45us/step - loss: 0.7446 - accuracy: 0.5474\n","Epoch 180/500\n","2459/2459 [==============================] - 0s 45us/step - loss: 0.7446 - accuracy: 0.5474\n","Epoch 181/500\n","2459/2459 [==============================] - 0s 43us/step - loss: 0.7511 - accuracy: 0.5486\n","Epoch 182/500\n","2459/2459 [==============================] - 0s 44us/step - loss: 0.7446 - accuracy: 0.5490\n","Epoch 183/500\n","2459/2459 [==============================] - 0s 44us/step - loss: 0.7446 - accuracy: 0.5490\n","Epoch 184/500\n","2459/2459 [==============================] - 0s 44us/step - loss: 0.7446 - accuracy: 0.5490\n","Epoch 185/500\n","2459/2459 [==============================] - 0s 45us/step - loss: 0.7446 - accuracy: 0.5490\n","Epoch 186/500\n","2459/2459 [==============================] - 0s 45us/step - loss: 0.7536 - accuracy: 0.5494\n","Epoch 187/500\n","2459/2459 [==============================] - 0s 45us/step - loss: 0.7446 - accuracy: 0.5498\n","Epoch 188/500\n","2459/2459 [==============================] - 0s 44us/step - loss: 0.7446 - accuracy: 0.5498\n","Epoch 189/500\n","2459/2459 [==============================] - 0s 45us/step - loss: 0.7446 - accuracy: 0.5498\n","Epoch 190/500\n","2459/2459 [==============================] - 0s 44us/step - loss: 0.7446 - accuracy: 0.5498\n","Epoch 191/500\n","2459/2459 [==============================] - 0s 45us/step - loss: 0.7446 - accuracy: 0.5498\n","Epoch 192/500\n","2459/2459 [==============================] - 0s 44us/step - loss: 0.7446 - accuracy: 0.5498\n","Epoch 193/500\n","2459/2459 [==============================] - 0s 44us/step - loss: 0.7446 - accuracy: 0.5498\n","Epoch 194/500\n","2459/2459 [==============================] - 0s 44us/step - loss: 0.7446 - accuracy: 0.5498\n","Epoch 195/500\n","2459/2459 [==============================] - 0s 44us/step - loss: 0.7446 - accuracy: 0.5498\n","Epoch 196/500\n","2459/2459 [==============================] - 0s 44us/step - loss: 0.7446 - accuracy: 0.5498\n","Epoch 197/500\n","2459/2459 [==============================] - 0s 45us/step - loss: 0.7446 - accuracy: 0.5498\n","Epoch 198/500\n","2459/2459 [==============================] - 0s 43us/step - loss: 0.7446 - accuracy: 0.5498\n","Epoch 199/500\n","2459/2459 [==============================] - 0s 45us/step - loss: 0.7446 - accuracy: 0.5498\n","Epoch 200/500\n","2459/2459 [==============================] - 0s 44us/step - loss: 0.7487 - accuracy: 0.5506\n","Epoch 201/500\n","2459/2459 [==============================] - 0s 43us/step - loss: 0.7446 - accuracy: 0.5506\n","Epoch 202/500\n","2459/2459 [==============================] - 0s 43us/step - loss: 0.7446 - accuracy: 0.5506\n","Epoch 203/500\n","2459/2459 [==============================] - 0s 44us/step - loss: 0.7446 - accuracy: 0.5506\n","Epoch 204/500\n","2459/2459 [==============================] - 0s 44us/step - loss: 0.7446 - accuracy: 0.5506\n","Epoch 205/500\n","2459/2459 [==============================] - 0s 43us/step - loss: 0.7446 - accuracy: 0.5506\n","Epoch 206/500\n","2459/2459 [==============================] - 0s 44us/step - loss: 0.7446 - accuracy: 0.5506\n","Epoch 207/500\n","2459/2459 [==============================] - 0s 44us/step - loss: 0.7446 - accuracy: 0.5506\n","Epoch 208/500\n","2459/2459 [==============================] - 0s 43us/step - loss: 0.7446 - accuracy: 0.5506\n","Epoch 209/500\n","2459/2459 [==============================] - 0s 45us/step - loss: 0.7446 - accuracy: 0.5506\n","Epoch 210/500\n","2459/2459 [==============================] - 0s 46us/step - loss: 0.7446 - accuracy: 0.5506\n","Epoch 211/500\n","2459/2459 [==============================] - 0s 44us/step - loss: 0.7446 - accuracy: 0.5506\n","Epoch 212/500\n","2459/2459 [==============================] - 0s 44us/step - loss: 0.7446 - accuracy: 0.5506\n","Epoch 213/500\n","2459/2459 [==============================] - 0s 44us/step - loss: 0.7446 - accuracy: 0.5506\n","Epoch 214/500\n","2459/2459 [==============================] - 0s 44us/step - loss: 0.7446 - accuracy: 0.5506\n","Epoch 215/500\n","2459/2459 [==============================] - 0s 44us/step - loss: 0.7446 - accuracy: 0.5506\n","Epoch 216/500\n","2459/2459 [==============================] - 0s 44us/step - loss: 0.7446 - accuracy: 0.5506\n","Epoch 217/500\n","2459/2459 [==============================] - 0s 45us/step - loss: 0.7446 - accuracy: 0.5506\n","Epoch 218/500\n","2459/2459 [==============================] - 0s 44us/step - loss: 0.7446 - accuracy: 0.5506\n","Epoch 219/500\n","2459/2459 [==============================] - 0s 45us/step - loss: 0.7446 - accuracy: 0.5506\n","Epoch 220/500\n","2459/2459 [==============================] - 0s 45us/step - loss: 0.7446 - accuracy: 0.5506\n","Epoch 221/500\n","2459/2459 [==============================] - 0s 46us/step - loss: 0.7446 - accuracy: 0.5506\n","Epoch 222/500\n","2459/2459 [==============================] - 0s 45us/step - loss: 0.7446 - accuracy: 0.5506\n","Epoch 223/500\n","2459/2459 [==============================] - 0s 45us/step - loss: 0.7446 - accuracy: 0.5506\n","Epoch 224/500\n","2459/2459 [==============================] - 0s 44us/step - loss: 0.7446 - accuracy: 0.5506\n","Epoch 225/500\n","2459/2459 [==============================] - 0s 44us/step - loss: 0.7446 - accuracy: 0.5506\n","Epoch 226/500\n","2459/2459 [==============================] - 0s 43us/step - loss: 0.7446 - accuracy: 0.5506\n","Epoch 227/500\n","2459/2459 [==============================] - 0s 41us/step - loss: 0.7446 - accuracy: 0.5506\n","Epoch 228/500\n","2459/2459 [==============================] - 0s 43us/step - loss: 0.7446 - accuracy: 0.5506\n","Epoch 229/500\n","2459/2459 [==============================] - 0s 42us/step - loss: 0.7446 - accuracy: 0.5506\n","Epoch 230/500\n","2459/2459 [==============================] - 0s 43us/step - loss: 0.7446 - accuracy: 0.5506\n","Epoch 231/500\n","2459/2459 [==============================] - 0s 45us/step - loss: 0.7446 - accuracy: 0.5506\n","Epoch 232/500\n","2459/2459 [==============================] - 0s 45us/step - loss: 0.7446 - accuracy: 0.5506\n","Epoch 233/500\n","2459/2459 [==============================] - 0s 45us/step - loss: 0.7446 - accuracy: 0.5506\n","Epoch 234/500\n","2459/2459 [==============================] - 0s 44us/step - loss: 0.7446 - accuracy: 0.5506\n","Epoch 235/500\n","2459/2459 [==============================] - 0s 45us/step - loss: 0.7446 - accuracy: 0.5506\n","Epoch 236/500\n","2459/2459 [==============================] - 0s 45us/step - loss: 0.7446 - accuracy: 0.5506\n","Epoch 237/500\n","2459/2459 [==============================] - 0s 44us/step - loss: 0.7446 - accuracy: 0.5506\n","Epoch 238/500\n","2459/2459 [==============================] - 0s 45us/step - loss: 0.7446 - accuracy: 0.5506\n","Epoch 239/500\n","2459/2459 [==============================] - 0s 44us/step - loss: 0.7446 - accuracy: 0.5506\n","Epoch 240/500\n","2459/2459 [==============================] - 0s 44us/step - loss: 0.7446 - accuracy: 0.5506\n","Epoch 241/500\n","2459/2459 [==============================] - 0s 44us/step - loss: 0.7446 - accuracy: 0.5506\n","Epoch 242/500\n","2459/2459 [==============================] - 0s 44us/step - loss: 0.7446 - accuracy: 0.5506\n","Epoch 243/500\n","2459/2459 [==============================] - 0s 44us/step - loss: 0.7491 - accuracy: 0.5514\n","Epoch 244/500\n","2459/2459 [==============================] - 0s 44us/step - loss: 0.7446 - accuracy: 0.5514\n","Epoch 245/500\n","2459/2459 [==============================] - 0s 44us/step - loss: 0.7446 - accuracy: 0.5514\n","Epoch 246/500\n","2459/2459 [==============================] - 0s 43us/step - loss: 0.7446 - accuracy: 0.5514\n","Epoch 247/500\n","2459/2459 [==============================] - 0s 43us/step - loss: 0.7446 - accuracy: 0.5514\n","Epoch 248/500\n","2459/2459 [==============================] - 0s 44us/step - loss: 0.7446 - accuracy: 0.5514\n","Epoch 249/500\n","2459/2459 [==============================] - 0s 44us/step - loss: 0.7446 - accuracy: 0.5514\n","Epoch 250/500\n","2459/2459 [==============================] - 0s 43us/step - loss: 0.7446 - accuracy: 0.5514\n","Epoch 251/500\n","2459/2459 [==============================] - 0s 43us/step - loss: 0.7446 - accuracy: 0.5514\n","Epoch 252/500\n","2459/2459 [==============================] - 0s 44us/step - loss: 0.7446 - accuracy: 0.5514\n","Epoch 253/500\n","2459/2459 [==============================] - 0s 43us/step - loss: 0.7446 - accuracy: 0.5514\n","Epoch 254/500\n","2459/2459 [==============================] - 0s 45us/step - loss: 0.7446 - accuracy: 0.5514\n","Epoch 255/500\n","2459/2459 [==============================] - 0s 45us/step - loss: 0.7446 - accuracy: 0.5514\n","Epoch 256/500\n","2459/2459 [==============================] - 0s 44us/step - loss: 0.7446 - accuracy: 0.5514\n","Epoch 257/500\n","2459/2459 [==============================] - 0s 46us/step - loss: 0.7446 - accuracy: 0.5514\n","Epoch 258/500\n","2459/2459 [==============================] - 0s 44us/step - loss: 0.7446 - accuracy: 0.5514\n","Epoch 259/500\n","2459/2459 [==============================] - 0s 44us/step - loss: 0.7446 - accuracy: 0.5514\n","Epoch 260/500\n","2459/2459 [==============================] - 0s 44us/step - loss: 0.7446 - accuracy: 0.5514\n","Epoch 261/500\n","2459/2459 [==============================] - 0s 45us/step - loss: 0.7446 - accuracy: 0.5514\n","Epoch 262/500\n","2459/2459 [==============================] - 0s 44us/step - loss: 0.7446 - accuracy: 0.5514\n","Epoch 263/500\n","2459/2459 [==============================] - 0s 44us/step - loss: 0.7446 - accuracy: 0.5514\n","Epoch 264/500\n","2459/2459 [==============================] - 0s 43us/step - loss: 0.7446 - accuracy: 0.5514\n","Epoch 265/500\n","2459/2459 [==============================] - 0s 44us/step - loss: 0.7446 - accuracy: 0.5514\n","Epoch 266/500\n","2459/2459 [==============================] - 0s 44us/step - loss: 0.7446 - accuracy: 0.5514\n","Epoch 267/500\n","2459/2459 [==============================] - 0s 44us/step - loss: 0.7446 - accuracy: 0.5514\n","Epoch 268/500\n","2459/2459 [==============================] - 0s 44us/step - loss: 0.7446 - accuracy: 0.5514\n","Epoch 269/500\n","2459/2459 [==============================] - 0s 43us/step - loss: 0.7446 - accuracy: 0.5514\n","Epoch 270/500\n","2459/2459 [==============================] - 0s 42us/step - loss: 0.7446 - accuracy: 0.5514\n","Epoch 271/500\n","2459/2459 [==============================] - 0s 43us/step - loss: 0.7446 - accuracy: 0.5514\n","Epoch 272/500\n","2459/2459 [==============================] - 0s 42us/step - loss: 0.7446 - accuracy: 0.5514\n","Epoch 273/500\n","2459/2459 [==============================] - 0s 43us/step - loss: 0.7446 - accuracy: 0.5514\n","Epoch 274/500\n","2459/2459 [==============================] - 0s 43us/step - loss: 0.7446 - accuracy: 0.5514\n","Epoch 275/500\n","2459/2459 [==============================] - 0s 44us/step - loss: 0.7446 - accuracy: 0.5514\n","Epoch 276/500\n","2459/2459 [==============================] - 0s 43us/step - loss: 0.7446 - accuracy: 0.5514\n","Epoch 277/500\n","2459/2459 [==============================] - 0s 43us/step - loss: 0.7446 - accuracy: 0.5514\n","Epoch 278/500\n","2459/2459 [==============================] - 0s 44us/step - loss: 0.7446 - accuracy: 0.5514\n","Epoch 279/500\n","2459/2459 [==============================] - 0s 44us/step - loss: 0.7487 - accuracy: 0.5514\n","Epoch 280/500\n","2459/2459 [==============================] - 0s 44us/step - loss: 0.7446 - accuracy: 0.5523\n","Epoch 281/500\n","2459/2459 [==============================] - 0s 43us/step - loss: 0.7446 - accuracy: 0.5523\n","Epoch 282/500\n","2459/2459 [==============================] - 0s 43us/step - loss: 0.7446 - accuracy: 0.5523\n","Epoch 283/500\n","2459/2459 [==============================] - 0s 43us/step - loss: 0.7499 - accuracy: 0.5531\n","Epoch 284/500\n","2459/2459 [==============================] - 0s 43us/step - loss: 0.7446 - accuracy: 0.5531\n","Epoch 285/500\n","2459/2459 [==============================] - 0s 44us/step - loss: 0.7446 - accuracy: 0.5531\n","Epoch 286/500\n","2459/2459 [==============================] - 0s 44us/step - loss: 0.7446 - accuracy: 0.5531\n","Epoch 287/500\n","2459/2459 [==============================] - 0s 46us/step - loss: 0.7446 - accuracy: 0.5531\n","Epoch 288/500\n","2459/2459 [==============================] - 0s 46us/step - loss: 0.7446 - accuracy: 0.5531\n","Epoch 289/500\n","2459/2459 [==============================] - 0s 45us/step - loss: 0.7446 - accuracy: 0.5531\n","Epoch 290/500\n","2459/2459 [==============================] - 0s 45us/step - loss: 0.7446 - accuracy: 0.5531\n","Epoch 291/500\n","2459/2459 [==============================] - 0s 46us/step - loss: 0.7446 - accuracy: 0.5531\n","Epoch 292/500\n","2459/2459 [==============================] - 0s 44us/step - loss: 0.7446 - accuracy: 0.5531\n","Epoch 293/500\n","2459/2459 [==============================] - 0s 44us/step - loss: 0.7446 - accuracy: 0.5531\n","Epoch 294/500\n","2459/2459 [==============================] - 0s 44us/step - loss: 0.7446 - accuracy: 0.5531\n","Epoch 295/500\n","2459/2459 [==============================] - 0s 44us/step - loss: 0.7446 - accuracy: 0.5531\n","Epoch 296/500\n","2459/2459 [==============================] - 0s 44us/step - loss: 0.7446 - accuracy: 0.5531\n","Epoch 297/500\n","2459/2459 [==============================] - 0s 44us/step - loss: 0.7446 - accuracy: 0.5531\n","Epoch 298/500\n","2459/2459 [==============================] - 0s 44us/step - loss: 0.7446 - accuracy: 0.5531\n","Epoch 299/500\n","2459/2459 [==============================] - 0s 44us/step - loss: 0.7446 - accuracy: 0.5531\n","Epoch 300/500\n","2459/2459 [==============================] - 0s 45us/step - loss: 0.7446 - accuracy: 0.5531\n","Epoch 301/500\n","2459/2459 [==============================] - 0s 44us/step - loss: 0.7446 - accuracy: 0.5531\n","Epoch 302/500\n","2459/2459 [==============================] - 0s 43us/step - loss: 0.7446 - accuracy: 0.5531\n","Epoch 303/500\n","2459/2459 [==============================] - 0s 44us/step - loss: 0.7446 - accuracy: 0.5531\n","Epoch 304/500\n","2459/2459 [==============================] - 0s 42us/step - loss: 0.7446 - accuracy: 0.5531\n","Epoch 305/500\n","2459/2459 [==============================] - 0s 43us/step - loss: 0.7446 - accuracy: 0.5531\n","Epoch 306/500\n","2459/2459 [==============================] - 0s 43us/step - loss: 0.7446 - accuracy: 0.5531\n","Epoch 307/500\n","2459/2459 [==============================] - 0s 43us/step - loss: 0.7446 - accuracy: 0.5531\n","Epoch 308/500\n","2459/2459 [==============================] - 0s 43us/step - loss: 0.7446 - accuracy: 0.5531\n","Epoch 309/500\n","2459/2459 [==============================] - 0s 43us/step - loss: 0.7446 - accuracy: 0.5531\n","Epoch 310/500\n","2459/2459 [==============================] - 0s 44us/step - loss: 0.7446 - accuracy: 0.5531\n","Epoch 311/500\n","2459/2459 [==============================] - 0s 43us/step - loss: 0.7446 - accuracy: 0.5531\n","Epoch 312/500\n","2459/2459 [==============================] - 0s 43us/step - loss: 0.7446 - accuracy: 0.5531\n","Epoch 313/500\n","2459/2459 [==============================] - 0s 44us/step - loss: 0.7446 - accuracy: 0.5531\n","Epoch 314/500\n","2459/2459 [==============================] - 0s 43us/step - loss: 0.7446 - accuracy: 0.5531\n","Epoch 315/500\n","2459/2459 [==============================] - 0s 44us/step - loss: 0.7446 - accuracy: 0.5531\n","Epoch 316/500\n","2459/2459 [==============================] - 0s 44us/step - loss: 0.7446 - accuracy: 0.5531\n","Epoch 317/500\n","2459/2459 [==============================] - 0s 43us/step - loss: 0.7446 - accuracy: 0.5531\n","Epoch 318/500\n","2459/2459 [==============================] - 0s 44us/step - loss: 0.7446 - accuracy: 0.5531\n","Epoch 319/500\n","2459/2459 [==============================] - 0s 44us/step - loss: 0.7446 - accuracy: 0.5531\n","Epoch 320/500\n","2459/2459 [==============================] - 0s 44us/step - loss: 0.7446 - accuracy: 0.5535\n","Epoch 321/500\n","2459/2459 [==============================] - 0s 42us/step - loss: 0.7446 - accuracy: 0.5535\n","Epoch 322/500\n","2459/2459 [==============================] - 0s 43us/step - loss: 0.7446 - accuracy: 0.5535\n","Epoch 323/500\n","2459/2459 [==============================] - 0s 44us/step - loss: 0.7446 - accuracy: 0.5535\n","Epoch 324/500\n","2459/2459 [==============================] - 0s 45us/step - loss: 0.7446 - accuracy: 0.5535\n","Epoch 325/500\n","2459/2459 [==============================] - 0s 44us/step - loss: 0.7446 - accuracy: 0.5535\n","Epoch 326/500\n","2459/2459 [==============================] - 0s 43us/step - loss: 0.7446 - accuracy: 0.5535\n","Epoch 327/500\n","2459/2459 [==============================] - 0s 44us/step - loss: 0.7446 - accuracy: 0.5535\n","Epoch 328/500\n","2459/2459 [==============================] - 0s 44us/step - loss: 0.7446 - accuracy: 0.5535\n","Epoch 329/500\n","2459/2459 [==============================] - 0s 43us/step - loss: 0.7446 - accuracy: 0.5535\n","Epoch 330/500\n","2459/2459 [==============================] - 0s 44us/step - loss: 0.7446 - accuracy: 0.5535\n","Epoch 331/500\n","2459/2459 [==============================] - 0s 44us/step - loss: 0.7446 - accuracy: 0.5535\n","Epoch 332/500\n","2459/2459 [==============================] - 0s 44us/step - loss: 0.7446 - accuracy: 0.5535\n","Epoch 333/500\n","2459/2459 [==============================] - 0s 43us/step - loss: 0.7446 - accuracy: 0.5539\n","Epoch 334/500\n","2459/2459 [==============================] - 0s 43us/step - loss: 0.7446 - accuracy: 0.5539\n","Epoch 335/500\n","2459/2459 [==============================] - 0s 44us/step - loss: 0.7446 - accuracy: 0.5539\n","Epoch 336/500\n","2459/2459 [==============================] - 0s 43us/step - loss: 0.7446 - accuracy: 0.5539\n","Epoch 337/500\n","2459/2459 [==============================] - 0s 44us/step - loss: 0.7446 - accuracy: 0.5539\n","Epoch 338/500\n","2459/2459 [==============================] - 0s 44us/step - loss: 0.7446 - accuracy: 0.5539\n","Epoch 339/500\n","2459/2459 [==============================] - 0s 44us/step - loss: 0.7446 - accuracy: 0.5539\n","Epoch 340/500\n","2459/2459 [==============================] - 0s 45us/step - loss: 0.7446 - accuracy: 0.5539\n","Epoch 341/500\n","2459/2459 [==============================] - 0s 43us/step - loss: 0.7446 - accuracy: 0.5539\n","Epoch 342/500\n","2459/2459 [==============================] - 0s 44us/step - loss: 0.7446 - accuracy: 0.5539\n","Epoch 343/500\n","2459/2459 [==============================] - 0s 45us/step - loss: 0.7446 - accuracy: 0.5539\n","Epoch 344/500\n","2459/2459 [==============================] - 0s 45us/step - loss: 0.7446 - accuracy: 0.5539\n","Epoch 345/500\n","2459/2459 [==============================] - 0s 45us/step - loss: 0.7446 - accuracy: 0.5539\n","Epoch 346/500\n","2459/2459 [==============================] - 0s 44us/step - loss: 0.7446 - accuracy: 0.5539\n","Epoch 347/500\n","2459/2459 [==============================] - 0s 43us/step - loss: 0.7446 - accuracy: 0.5539\n","Epoch 348/500\n","2459/2459 [==============================] - 0s 45us/step - loss: 0.7446 - accuracy: 0.5539\n","Epoch 349/500\n","2459/2459 [==============================] - 0s 45us/step - loss: 0.7446 - accuracy: 0.5539\n","Epoch 350/500\n","2459/2459 [==============================] - 0s 44us/step - loss: 0.7446 - accuracy: 0.5539\n","Epoch 351/500\n","2459/2459 [==============================] - 0s 44us/step - loss: 0.7446 - accuracy: 0.5539\n","Epoch 352/500\n","2459/2459 [==============================] - 0s 45us/step - loss: 0.7446 - accuracy: 0.5539\n","Epoch 353/500\n","2459/2459 [==============================] - 0s 44us/step - loss: 0.7446 - accuracy: 0.5539\n","Epoch 354/500\n","2459/2459 [==============================] - 0s 43us/step - loss: 0.7446 - accuracy: 0.5539\n","Epoch 355/500\n","2459/2459 [==============================] - 0s 45us/step - loss: 0.7446 - accuracy: 0.5539\n","Epoch 356/500\n","2459/2459 [==============================] - 0s 45us/step - loss: 0.7446 - accuracy: 0.5539\n","Epoch 357/500\n","2459/2459 [==============================] - 0s 45us/step - loss: 0.7446 - accuracy: 0.5539\n","Epoch 358/500\n","2459/2459 [==============================] - 0s 44us/step - loss: 0.7446 - accuracy: 0.5539\n","Epoch 359/500\n","2459/2459 [==============================] - 0s 45us/step - loss: 0.7446 - accuracy: 0.5539\n","Epoch 360/500\n","2459/2459 [==============================] - 0s 44us/step - loss: 0.7446 - accuracy: 0.5539\n","Epoch 361/500\n","2459/2459 [==============================] - 0s 43us/step - loss: 0.7446 - accuracy: 0.5539\n","Epoch 362/500\n","2459/2459 [==============================] - 0s 45us/step - loss: 0.7446 - accuracy: 0.5539\n","Epoch 363/500\n","2459/2459 [==============================] - 0s 43us/step - loss: 0.7446 - accuracy: 0.5539\n","Epoch 364/500\n","2459/2459 [==============================] - 0s 44us/step - loss: 0.7446 - accuracy: 0.5539\n","Epoch 365/500\n","2459/2459 [==============================] - 0s 45us/step - loss: 0.7446 - accuracy: 0.5539\n","Epoch 366/500\n","2459/2459 [==============================] - 0s 44us/step - loss: 0.7446 - accuracy: 0.5539\n","Epoch 367/500\n","2459/2459 [==============================] - 0s 45us/step - loss: 0.7446 - accuracy: 0.5539\n","Epoch 368/500\n","2459/2459 [==============================] - 0s 45us/step - loss: 0.7446 - accuracy: 0.5539\n","Epoch 369/500\n","2459/2459 [==============================] - 0s 45us/step - loss: 0.7446 - accuracy: 0.5539\n","Epoch 370/500\n","2459/2459 [==============================] - 0s 44us/step - loss: 0.7446 - accuracy: 0.5539\n","Epoch 371/500\n","2459/2459 [==============================] - 0s 45us/step - loss: 0.7446 - accuracy: 0.5539\n","Epoch 372/500\n","2459/2459 [==============================] - 0s 44us/step - loss: 0.7446 - accuracy: 0.5539\n","Epoch 373/500\n","2459/2459 [==============================] - 0s 45us/step - loss: 0.7446 - accuracy: 0.5539\n","Epoch 374/500\n","2459/2459 [==============================] - 0s 45us/step - loss: 0.7446 - accuracy: 0.5539\n","Epoch 375/500\n","2459/2459 [==============================] - 0s 44us/step - loss: 0.7446 - accuracy: 0.5539\n","Epoch 376/500\n","2459/2459 [==============================] - 0s 44us/step - loss: 0.7446 - accuracy: 0.5539\n","Epoch 377/500\n","2459/2459 [==============================] - 0s 45us/step - loss: 0.7446 - accuracy: 0.5539\n","Epoch 378/500\n","2459/2459 [==============================] - 0s 45us/step - loss: 0.7446 - accuracy: 0.5539\n","Epoch 379/500\n","2459/2459 [==============================] - 0s 46us/step - loss: 0.7446 - accuracy: 0.5539\n","Epoch 380/500\n","2459/2459 [==============================] - 0s 45us/step - loss: 0.7475 - accuracy: 0.5547\n","Epoch 381/500\n","2459/2459 [==============================] - 0s 44us/step - loss: 0.7446 - accuracy: 0.5555\n","Epoch 382/500\n","2459/2459 [==============================] - 0s 45us/step - loss: 0.7446 - accuracy: 0.5555\n","Epoch 383/500\n","2459/2459 [==============================] - 0s 45us/step - loss: 0.7446 - accuracy: 0.5555\n","Epoch 384/500\n","2459/2459 [==============================] - 0s 45us/step - loss: 0.7446 - accuracy: 0.5555\n","Epoch 385/500\n","2459/2459 [==============================] - 0s 45us/step - loss: 0.7446 - accuracy: 0.5555\n","Epoch 386/500\n","2459/2459 [==============================] - 0s 45us/step - loss: 0.7446 - accuracy: 0.5555\n","Epoch 387/500\n","2459/2459 [==============================] - 0s 46us/step - loss: 0.7446 - accuracy: 0.5555\n","Epoch 388/500\n","2459/2459 [==============================] - 0s 45us/step - loss: 0.7446 - accuracy: 0.5555\n","Epoch 389/500\n","2459/2459 [==============================] - 0s 45us/step - loss: 0.7446 - accuracy: 0.5555\n","Epoch 390/500\n","2459/2459 [==============================] - 0s 45us/step - loss: 0.7446 - accuracy: 0.5555\n","Epoch 391/500\n","2459/2459 [==============================] - 0s 44us/step - loss: 0.7446 - accuracy: 0.5555\n","Epoch 392/500\n","2459/2459 [==============================] - 0s 44us/step - loss: 0.7446 - accuracy: 0.5555\n","Epoch 393/500\n","2459/2459 [==============================] - 0s 45us/step - loss: 0.7446 - accuracy: 0.5555\n","Epoch 394/500\n","2459/2459 [==============================] - 0s 43us/step - loss: 0.7446 - accuracy: 0.5555\n","Epoch 395/500\n","2459/2459 [==============================] - 0s 44us/step - loss: 0.7446 - accuracy: 0.5555\n","Epoch 396/500\n","2459/2459 [==============================] - 0s 45us/step - loss: 0.7446 - accuracy: 0.5555\n","Epoch 397/500\n","2459/2459 [==============================] - 0s 44us/step - loss: 0.7446 - accuracy: 0.5555\n","Epoch 398/500\n","2459/2459 [==============================] - 0s 44us/step - loss: 0.7446 - accuracy: 0.5555\n","Epoch 399/500\n","2459/2459 [==============================] - 0s 44us/step - loss: 0.7446 - accuracy: 0.5555\n","Epoch 400/500\n","2459/2459 [==============================] - 0s 45us/step - loss: 0.7446 - accuracy: 0.5555\n","Epoch 401/500\n","2459/2459 [==============================] - 0s 45us/step - loss: 0.7446 - accuracy: 0.5555\n","Epoch 402/500\n","2459/2459 [==============================] - 0s 44us/step - loss: 0.7446 - accuracy: 0.5555\n","Epoch 403/500\n","2459/2459 [==============================] - 0s 45us/step - loss: 0.7446 - accuracy: 0.5555\n","Epoch 404/500\n","2459/2459 [==============================] - 0s 44us/step - loss: 0.7446 - accuracy: 0.5555\n","Epoch 405/500\n","2459/2459 [==============================] - 0s 43us/step - loss: 0.7446 - accuracy: 0.5555\n","Epoch 406/500\n","2459/2459 [==============================] - 0s 43us/step - loss: 0.7446 - accuracy: 0.5555\n","Epoch 407/500\n","2459/2459 [==============================] - 0s 43us/step - loss: 0.7446 - accuracy: 0.5555\n","Epoch 408/500\n","2459/2459 [==============================] - 0s 44us/step - loss: 0.7479 - accuracy: 0.5555\n","Epoch 409/500\n","2459/2459 [==============================] - 0s 45us/step - loss: 0.7446 - accuracy: 0.5563\n","Epoch 410/500\n","2459/2459 [==============================] - 0s 44us/step - loss: 0.7446 - accuracy: 0.5563\n","Epoch 411/500\n","2459/2459 [==============================] - 0s 44us/step - loss: 0.7446 - accuracy: 0.5563\n","Epoch 412/500\n","2459/2459 [==============================] - 0s 43us/step - loss: 0.7487 - accuracy: 0.5571\n","Epoch 413/500\n","2459/2459 [==============================] - 0s 44us/step - loss: 0.7466 - accuracy: 0.5571\n","Epoch 414/500\n","2459/2459 [==============================] - 0s 43us/step - loss: 0.7446 - accuracy: 0.5575\n","Epoch 415/500\n","2459/2459 [==============================] - 0s 44us/step - loss: 0.7446 - accuracy: 0.5575\n","Epoch 416/500\n","2459/2459 [==============================] - 0s 45us/step - loss: 0.7446 - accuracy: 0.5575\n","Epoch 417/500\n","2459/2459 [==============================] - 0s 42us/step - loss: 0.7490 - accuracy: 0.5575\n","Epoch 418/500\n","2459/2459 [==============================] - 0s 43us/step - loss: 0.7446 - accuracy: 0.5588\n","Epoch 419/500\n","2459/2459 [==============================] - 0s 44us/step - loss: 0.7446 - accuracy: 0.5588\n","Epoch 420/500\n","2459/2459 [==============================] - 0s 44us/step - loss: 0.7446 - accuracy: 0.5588\n","Epoch 421/500\n","2459/2459 [==============================] - 0s 43us/step - loss: 0.7446 - accuracy: 0.5588\n","Epoch 422/500\n","2459/2459 [==============================] - 0s 43us/step - loss: 0.7446 - accuracy: 0.5588\n","Epoch 423/500\n","2459/2459 [==============================] - 0s 42us/step - loss: 0.7446 - accuracy: 0.5588\n","Epoch 424/500\n","2459/2459 [==============================] - 0s 43us/step - loss: 0.7446 - accuracy: 0.5588\n","Epoch 425/500\n","2459/2459 [==============================] - 0s 43us/step - loss: 0.7446 - accuracy: 0.5588\n","Epoch 426/500\n","2459/2459 [==============================] - 0s 43us/step - loss: 0.7446 - accuracy: 0.5588\n","Epoch 427/500\n","2459/2459 [==============================] - 0s 43us/step - loss: 0.7446 - accuracy: 0.5588\n","Epoch 428/500\n","2459/2459 [==============================] - 0s 43us/step - loss: 0.7446 - accuracy: 0.5588\n","Epoch 429/500\n","2459/2459 [==============================] - 0s 42us/step - loss: 0.7446 - accuracy: 0.5588\n","Epoch 430/500\n","2459/2459 [==============================] - 0s 43us/step - loss: 0.7446 - accuracy: 0.5588\n","Epoch 431/500\n","2459/2459 [==============================] - 0s 43us/step - loss: 0.7446 - accuracy: 0.5588\n","Epoch 432/500\n","2459/2459 [==============================] - 0s 43us/step - loss: 0.7446 - accuracy: 0.5588\n","Epoch 433/500\n","2459/2459 [==============================] - 0s 42us/step - loss: 0.7446 - accuracy: 0.5588\n","Epoch 434/500\n","2459/2459 [==============================] - 0s 43us/step - loss: 0.7446 - accuracy: 0.5588\n","Epoch 435/500\n","2459/2459 [==============================] - 0s 44us/step - loss: 0.7446 - accuracy: 0.5588\n","Epoch 436/500\n","2459/2459 [==============================] - 0s 44us/step - loss: 0.7446 - accuracy: 0.5588\n","Epoch 437/500\n","2459/2459 [==============================] - 0s 44us/step - loss: 0.7446 - accuracy: 0.5588\n","Epoch 438/500\n","2459/2459 [==============================] - 0s 44us/step - loss: 0.7446 - accuracy: 0.5588\n","Epoch 439/500\n","2459/2459 [==============================] - 0s 43us/step - loss: 0.7446 - accuracy: 0.5588\n","Epoch 440/500\n","2459/2459 [==============================] - 0s 45us/step - loss: 0.7495 - accuracy: 0.5588\n","Epoch 441/500\n","2459/2459 [==============================] - 0s 42us/step - loss: 0.7446 - accuracy: 0.5592\n","Epoch 442/500\n","2459/2459 [==============================] - 0s 44us/step - loss: 0.7446 - accuracy: 0.5592\n","Epoch 443/500\n","2459/2459 [==============================] - 0s 44us/step - loss: 0.7446 - accuracy: 0.5592\n","Epoch 444/500\n","2459/2459 [==============================] - 0s 43us/step - loss: 0.7446 - accuracy: 0.5592\n","Epoch 445/500\n","2459/2459 [==============================] - 0s 44us/step - loss: 0.7446 - accuracy: 0.5592\n","Epoch 446/500\n","2459/2459 [==============================] - 0s 44us/step - loss: 0.7446 - accuracy: 0.5592\n","Epoch 447/500\n","2459/2459 [==============================] - 0s 46us/step - loss: 0.7446 - accuracy: 0.5592\n","Epoch 448/500\n","2459/2459 [==============================] - 0s 45us/step - loss: 0.7446 - accuracy: 0.5592\n","Epoch 449/500\n","2459/2459 [==============================] - 0s 45us/step - loss: 0.7446 - accuracy: 0.5592\n","Epoch 450/500\n","2459/2459 [==============================] - 0s 44us/step - loss: 0.7446 - accuracy: 0.5592\n","Epoch 451/500\n","2459/2459 [==============================] - 0s 44us/step - loss: 0.7446 - accuracy: 0.5592\n","Epoch 452/500\n","2459/2459 [==============================] - 0s 45us/step - loss: 0.7446 - accuracy: 0.5592\n","Epoch 453/500\n","2459/2459 [==============================] - 0s 46us/step - loss: 0.7446 - accuracy: 0.5592\n","Epoch 454/500\n","2459/2459 [==============================] - 0s 45us/step - loss: 0.7446 - accuracy: 0.5592\n","Epoch 455/500\n","2459/2459 [==============================] - 0s 44us/step - loss: 0.7446 - accuracy: 0.5592\n","Epoch 456/500\n","2459/2459 [==============================] - 0s 44us/step - loss: 0.7446 - accuracy: 0.5592\n","Epoch 457/500\n","2459/2459 [==============================] - 0s 44us/step - loss: 0.7446 - accuracy: 0.5592\n","Epoch 458/500\n","2459/2459 [==============================] - 0s 45us/step - loss: 0.7446 - accuracy: 0.5592\n","Epoch 459/500\n","2459/2459 [==============================] - 0s 45us/step - loss: 0.7446 - accuracy: 0.5592\n","Epoch 460/500\n","2459/2459 [==============================] - 0s 45us/step - loss: 0.7446 - accuracy: 0.5592\n","Epoch 461/500\n","2459/2459 [==============================] - 0s 45us/step - loss: 0.7446 - accuracy: 0.5592\n","Epoch 462/500\n","2459/2459 [==============================] - 0s 44us/step - loss: 0.7446 - accuracy: 0.5592\n","Epoch 463/500\n","2459/2459 [==============================] - 0s 42us/step - loss: 0.7446 - accuracy: 0.5592\n","Epoch 464/500\n","2459/2459 [==============================] - 0s 43us/step - loss: 0.7446 - accuracy: 0.5592\n","Epoch 465/500\n","2459/2459 [==============================] - 0s 44us/step - loss: 0.7446 - accuracy: 0.5592\n","Epoch 466/500\n","2459/2459 [==============================] - 0s 44us/step - loss: 0.7446 - accuracy: 0.5592\n","Epoch 467/500\n","2459/2459 [==============================] - 0s 45us/step - loss: 0.7446 - accuracy: 0.5592\n","Epoch 468/500\n","2459/2459 [==============================] - 0s 44us/step - loss: 0.7446 - accuracy: 0.5592\n","Epoch 469/500\n","2459/2459 [==============================] - 0s 44us/step - loss: 0.7446 - accuracy: 0.5592\n","Epoch 470/500\n","2459/2459 [==============================] - 0s 45us/step - loss: 0.7446 - accuracy: 0.5592\n","Epoch 471/500\n","2459/2459 [==============================] - 0s 43us/step - loss: 0.7446 - accuracy: 0.5592\n","Epoch 472/500\n","2459/2459 [==============================] - 0s 43us/step - loss: 0.7446 - accuracy: 0.5592\n","Epoch 473/500\n","2459/2459 [==============================] - 0s 44us/step - loss: 0.7446 - accuracy: 0.5592\n","Epoch 474/500\n","2459/2459 [==============================] - 0s 45us/step - loss: 0.7446 - accuracy: 0.5592\n","Epoch 475/500\n","2459/2459 [==============================] - 0s 45us/step - loss: 0.7446 - accuracy: 0.5592\n","Epoch 476/500\n","2459/2459 [==============================] - 0s 44us/step - loss: 0.7446 - accuracy: 0.5592\n","Epoch 477/500\n","2459/2459 [==============================] - 0s 43us/step - loss: 0.7446 - accuracy: 0.5592\n","Epoch 478/500\n","2459/2459 [==============================] - 0s 44us/step - loss: 0.7446 - accuracy: 0.5592\n","Epoch 479/500\n","2459/2459 [==============================] - 0s 44us/step - loss: 0.7446 - accuracy: 0.5592\n","Epoch 480/500\n","2459/2459 [==============================] - 0s 43us/step - loss: 0.7446 - accuracy: 0.5592\n","Epoch 481/500\n","2459/2459 [==============================] - 0s 42us/step - loss: 0.7446 - accuracy: 0.5592\n","Epoch 482/500\n","2459/2459 [==============================] - 0s 42us/step - loss: 0.7446 - accuracy: 0.5592\n","Epoch 483/500\n","2459/2459 [==============================] - 0s 43us/step - loss: 0.7446 - accuracy: 0.5592\n","Epoch 484/500\n","2459/2459 [==============================] - 0s 42us/step - loss: 0.7446 - accuracy: 0.5592\n","Epoch 485/500\n","2459/2459 [==============================] - 0s 44us/step - loss: 0.7446 - accuracy: 0.5592\n","Epoch 486/500\n","2459/2459 [==============================] - 0s 43us/step - loss: 0.7446 - accuracy: 0.5592\n","Epoch 487/500\n","2459/2459 [==============================] - 0s 43us/step - loss: 0.7446 - accuracy: 0.5592\n","Epoch 488/500\n","2459/2459 [==============================] - 0s 45us/step - loss: 0.7446 - accuracy: 0.5592\n","Epoch 489/500\n","2459/2459 [==============================] - 0s 43us/step - loss: 0.7446 - accuracy: 0.5592\n","Epoch 490/500\n","2459/2459 [==============================] - 0s 43us/step - loss: 0.7446 - accuracy: 0.5592\n","Epoch 491/500\n","2459/2459 [==============================] - 0s 43us/step - loss: 0.7446 - accuracy: 0.5592\n","Epoch 492/500\n","2459/2459 [==============================] - 0s 44us/step - loss: 0.7446 - accuracy: 0.5592\n","Epoch 493/500\n","2459/2459 [==============================] - 0s 44us/step - loss: 0.7446 - accuracy: 0.5592\n","Epoch 494/500\n","2459/2459 [==============================] - 0s 43us/step - loss: 0.7446 - accuracy: 0.5592\n","Epoch 495/500\n","2459/2459 [==============================] - 0s 43us/step - loss: 0.7446 - accuracy: 0.5592\n","Epoch 496/500\n","2459/2459 [==============================] - 0s 43us/step - loss: 0.7446 - accuracy: 0.5592\n","Epoch 497/500\n","2459/2459 [==============================] - 0s 44us/step - loss: 0.7446 - accuracy: 0.5592\n","Epoch 498/500\n","2459/2459 [==============================] - 0s 43us/step - loss: 0.7446 - accuracy: 0.5592\n","Epoch 499/500\n","2459/2459 [==============================] - 0s 43us/step - loss: 0.7446 - accuracy: 0.5592\n","Epoch 500/500\n","2459/2459 [==============================] - 0s 44us/step - loss: 0.7446 - accuracy: 0.5592\n","Test Accuracy: 0.57\n"],"name":"stdout"}]}]}